{
  "metadata": {
    "name": "Final",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfile_name_311 \u003d \u0027/user/CS-GY-6513/project_data/data-cityofnewyork-us.erm2-nwe9.csv\u0027\nNYPD_complaint_dataset \u003d \u0027/user/CS-GY-6513/project_data/data-cityofnewyork-us.qgea-i56i.csv\u0027\nNYPD_arrest_dataset_name \u003d \u0027/user/CS-GY-6513/project_data/data-cityofnewyork-us.uip8-fykc.csv\u0027\nshooting_dataset_name \u003d \u0027/user/CS-GY-6513/project_data/data-cityofnewyork-us.833y-fsy8.csv\u0027\nbikes_building_dataset_name \u003d \u0027/user/CS-GY-6513/project_data/data-cityofnewyork-us.scjj-6yaf.csv\u0027\nNYPD_B_summons \u003d \u0027/user/CS-GY-6513/project_data/data-cityofnewyork-us.57p3-pdcj.csv\u0027\nparking_dataset_name \u003d \u0027/user/CS-GY-6513/project_data/data-cityofnewyork-us.nc67-uf89.csv\u0027\ncollisions_dataset_name \u003d \u0027/user/CS-GY-6513/project_data/data-cityofnewyork-us.h9gi-nx95.csv\u0027\nflu_vac_dataset_name \u003d \u0027/user/CS-GY-6513/project_data/data-cityofnewyork-us.w9ei-idxz.csv\u0027\nwifi_dataset_name \u003d \u0027/user/CS-GY-6513/project_data/data-cityofnewyork-us.yjub-udmw.csv\u0027\nhousing_buildings_dataset_name \u003d \u0027/user/CS-GY-6513/project_data/data-cityofnewyork-us.hg8x-zxpr.csv\u0027\n\ndata \u003d spark.read.option(\"header\",True) \\\n     .csv(file_name_311)\n     \nNYPD_complaint_df \u003d spark.read.option(\"header\",True) \\\n     .csv(NYPD_complaint_dataset)\n     \nNYPD_arrests_df \u003d spark.read.option(\"header\",True) \\\n     .csv(NYPD_arrest_dataset_name)\n     \nshooting_dataset_df \u003d  spark.read.option(\"header\",True) \\\n     .csv(shooting_dataset_name)\n     \nbikes_building_df \u003d  spark.read.option(\"header\",True) \\\n     .csv(bikes_building_dataset_name)\n     \nNYPD_B_summons_df \u003d spark.read.option(\"header\",True) \\\n     .csv(NYPD_B_summons)\n     \nparking_df \u003d spark.read.option(\"header\",True) \\\n     .csv(parking_dataset_name)\n     \ncollisions_df \u003d spark.read.option(\"header\",True) \\\n     .csv(collisions_dataset_name)\n     \nflu_vac_df \u003d  spark.read.option(\"header\",True) \\\n     .csv(flu_vac_dataset_name)\n     \nwifi_df \u003d spark.read.option(\"header\",True) \\\n     .csv(wifi_dataset_name)\n     \nhousing_buildings_df \u003d spark.read.option(\"header\",True) \\\n     .csv(housing_buildings_dataset_name)\n     \n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndata.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndef stringtoI(data_new,zip_code):\n    \n    data_new \u003d data_new.withColumn(zip_code, data_new[zip_code].cast(IntegerType()))\n    return data_new"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nzip_code \u003d \"Incident zip\"\nborough \u003d \"Borough\"\ncity \u003d \"City\"\nkey \u003d \"Unique Key\""
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndata \u003d stringtoI(data,zip_code)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndata.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndef dfCreation(data_new):\n    #This method is called for every other dataset other than 311 that is being checked using the same techniques of 311\n    rdd \u003d data_new.rdd\n    #This is our 311 df that will be used throughout the cleaning of 311 dataset\n    df \u003d spark.createDataFrame(rdd, data_new.schema)\n    return df\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf \u003d dfCreation(data)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef inc_zipToB_map(df,zip_code,key,borough):\n    print(\"Incorrect Data for BRONX:\\n\")\n    df.where((col(zip_code) \u003e 10450) \u0026 (col(zip_code) \u003c 10475) \u0026 (upper(col(borough)) !\u003d \"BRONX\")).select(key,zip_code,borough).show()\n    print(\"Incorrect Data for BROOKLYN:\\n\")\n    df.where((col(zip_code) \u003e 11200) \u0026 (col(zip_code) \u003c 11240) \u0026 (upper(col(borough)) !\u003d \"BROOKLYN\")).select(key,borough).show()\n    print(\"Incorrect Data for MANHATTAN:\\n\")\n    df.where((col(zip_code) \u003e 10000) \u0026 (col(zip_code) \u003c 10280) \u0026 (upper(col(borough)) !\u003d \"MANHATTAN\")).select(key,borough).show()\n    print(\"Incorrect Data for STATEN ISLAND:\\n\")\n    df.where((col(zip_code) \u003e 10300) \u0026 (col(zip_code) \u003c 10315) \u0026 (upper(col(borough)) !\u003d \"STATEN ISLAND\")).select(key,borough).show()\n    print(\"Incorrect Data for QUEENS:\\n\")\n    df.where((col(zip_code) \u003e 11350) \u0026 (col(zip_code) \u003c 11700) \u0026 (upper(col(borough)) !\u003d \"QUEENS\")).select(key,borough).show()"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ninc_zipToB_map(df,zip_code,key,borough)"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef validate_borough(df, zip_code, borough):\n    df \u003d df.withColumn(borough, when((col(zip_code) \u003e 11350) \u0026 (col(zip_code)\u003c11700),\"QUEENS\")\n                   .when((col(zip_code) \u003e 11200) \u0026 (col(zip_code)\u003c11240),\"BROOKLYN\")\n                   .when((col(zip_code)\u003e10450) \u0026 (col(zip_code)\u003c10475),\"BRONX\")\n                   .when((col(zip_code)\u003e10000) \u0026 (col(zip_code)\u003c10280),\"MANHATTAN\")\n                   .when((col(zip_code)\u003e10300) \u0026 (col(zip_code)\u003c10315),\"STATEN ISLAND\")\n                   .otherwise(col(borough)))\n    return df"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndef inc_zipToB_map_result(df,zip_code,key,borough):\n    print(\"Incorrect Data for BRONX:\\n\")\n    df.where((col(zip_code) \u003e 10450) \u0026 (col(zip_code) \u003c 10475)).select(key,zip_code,borough).show(100)\n    print(\"Incorrect Data for BROOKLYN:\\n\")\n    df.where((col(zip_code) \u003e 11200) \u0026 (col(zip_code) \u003c 11240) \u0026 (col(borough) \u003d\u003d \"BROOKLYN\")).select(key,borough).show()\n    print(\"Incorrect Data for MANHATTAN:\\n\")\n    df.where((col(zip_code) \u003e 10000) \u0026 (col(zip_code) \u003c 10280) \u0026 (col(borough) \u003d\u003d \"MANHATTAN\")).select(key,borough).show()\n    print(\"Incorrect Data for STATEN ISLAND:\\n\")\n    df.where((col(zip_code) \u003e 10300) \u0026 (col(zip_code) \u003c 10315) \u0026 (col(borough) \u003d\u003d \"STATEN ISLAND\")).select(key,borough).show()\n    print(\"Incorrect Data for QUEENS:\\n\")\n    df.where((col(zip_code) \u003e 11350) \u0026 (col(zip_code) \u003c 11700) \u0026 (col(borough) \u003d\u003d \"QUEENS\")).select(key,borough).show()"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf \u003d validate_borough(df, zip_code, borough)"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# NOTE: we are manually checking precision on top 100 rows for Bronx borough only\n\ninc_zipToB_map_result(df,zip_code,key,borough)"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef missing_city_data(df,city,borough):\n    print(\"Missing city data:\\n\")\n    df.where((col(\"City\") \u003d\u003d\"N/A\") | (col(\"City\")\u003d\u003d\"NA\") | (col(\"City\").isNull())).select(\"Borough\", \"City\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nmissing_city_data(df,city,borough)"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef standardize_city(df,city,borough):\n    df \u003d df.withColumn(city, when(((col(city).isNull()) | (col(city)\u003d\u003d\"N/A\") | (col(city)\u003d\u003d\"NA\")) \u0026 (col(borough).isNull()),\"New York\")\n           .when(((col(city).isNull()) | (col(city)\u003d\u003d\"N/A\") | (col(city)\u003d\u003d\"NA\")) \u0026 (col(borough).isNotNull()), col(borough))\n           .otherwise(col(city)))\n        \n    return df"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d standardize_city(df, city, borough)"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndef cleanNonNYC(df, city):\n    df \u003d df.where(col(city).toUpperCase() \u003d\u003d \"NEW YORK\" | col(city))"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nmissing_city_data(df,city,borough)"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndef drop_x_y(df):\n    df \u003d df.drop(\u0027X Coordinate (State Plane)\u0027)\n    df \u003d df.drop(\u0027Y Coordinate (State Plane)\u0027)\n    return df"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf \u003d drop_x_y(df)\ndf.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndef drop_lat_long(df):\n    df \u003d df.drop(\u0027\u0027)\n    df \u003d df.drop(\u0027Longitude\u0027)\n    return df"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf \u003d drop_lat_long(df)\ndf.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ncs1 \u003d \"Cross Street 1\"\ncs2 \u003d \"Cross Street 2\"\nis1 \u003d \"Intersection Street 1\"\nis2 \u003d \"Intersection Street 2\"\nparkb \u003d \"Park Borough\""
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef street_merge(df, cs1, cs2, is1, is2):\n    df \u003d df.withColumn(cs1, when((col(cs1).isNull()), col(is1))\n            .otherwise(col(cs1)))\n            \n    df \u003d df.withColumn(\"cs2\", when((col(cs2).isNull()), col(is2))\n            .otherwise(col(cs2)))\n            \n    df \u003d df.drop(is1, is2)\n    \n    return df"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf \u003d street_merge(df, cs1, cs2, is1, is2)\ndf.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef parkb_merge(df,borough,parkb):\n    df \u003d df.withColumn(borough, when((col(borough).isNull()), col(parkb))\n            .otherwise(col(borough)))\n            \n    df \u003d df.drop(parkb)\n    return df"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf \u003d parkb_merge(df, borough, parkb)\ndf.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf.where((col(\"Created Date\")\u003ecurrent_date())).select(\"Created Date\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# turning the code above into a fucntion \n\ndef show_dates_in_the_future(data_frame, date_col_name):\n    data_frame.where((col(date_col_name)\u003ecurrent_date())).select(date_col_name).show()"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.filter(df[\"Created Date\"] \u003c\u003d current_date())"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef update_close_dt(df, closed_dt\u003d\"Closed Date\", status\u003d\"Status\", res_aud\u003d\"Resolution Action Updated Date\"):\n    df \u003d df.withColumn(closed_dt, when((col(closed_dt).isNull()) \u0026 (col(status)\u003d\u003d\u0027Closed\u0027) \u0026(col(res_aud).isNotNull()),col(res_aud)).otherwise(col(closed_dt)))\n\n    df \u003d df.withColumn(res_aud, when((col(res_aud).isNull()) \u0026 (col(status)\u003d\u003d\u0027Closed\u0027) \u0026(col(closed_dt).isNotNull()),col(closed_dt)).otherwise(col(res_aud)))\n    return df\n"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf \u003d update_close_dt(df)"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndef agency_incorrect_display(df):\n    df.where((col(\"Agency\")\u003d\u003d \"NYPD\") \u0026 (col(\"Agency Name\") !\u003d \"New York City Police Department\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"HPD\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Housing Preservation and Development\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DOT\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Transportation\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DSNY\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Sanitation\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DEP\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Environmental Protection\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DOB\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Buildings\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DPR\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Parks and Recreation\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DOHMH\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Health and Mental Hygiene\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DOF\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Finance\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"TLC\") \u0026 (col(\"Agency Name\") !\u003d \"Taxi and Limouisine Commission\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DHS\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Homeless Services\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DCA\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Consumer Affairs\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"HRA\") \u0026 (col(\"Agency Name\") !\u003d \"Human Resources Administration\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DFTA\") \u0026 (col(\"Agency Name\") !\u003d \"Department for the Aging\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"MAYORâ€  S OFFICE OF SPECIAL ENFORCEMENT\") \u0026 (col(\"Agency Name\") !\u003d \"Mayor\u0027s Office of Special Enforcement\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"EDC\") \u0026 (col(\"Agency Name\") !\u003d \"Economic Development Corporation\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DOE\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Education\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"3-1-1\") \u0026 (col(\"Agency Name\") !\u003d \"3-1-1 Call Center\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"NYCEM\") \u0026 (col(\"Agency Name\") !\u003d \"NYC Emergency Management\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DOITT\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Information Technology and Telecommunications\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DCAS\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Citywide Administrative Services\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"ACS\") \u0026 (col(\"Agency Name\") !\u003d \"Administration for Children\u0027s Services\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"TAX\") \u0026 (col(\"Agency Name\") !\u003d \"Tax Commission\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DVS\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Veteran\u0027s Services\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DCP\") \u0026 (col(\"Agency Name\") !\u003d \"Department of City Plannning\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"DORIS\") \u0026 (col(\"Agency Name\") !\u003d \"Department of Records and Information Services\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"FDNY\") \u0026 (col(\"Agency Name\") !\u003d \"Fire Department of New York\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"TAT\") \u0026 (col(\"Agency Name\") !\u003d \"Tax Appeals Tribunal\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"COIB\") \u0026 (col(\"Agency Name\") !\u003d \"Conflicts of Interest Board\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"CEO\") \u0026 (col(\"Agency Name\") !\u003d \"Center for Economic Opportunity\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"MOC\") \u0026 (col(\"Agency Name\") !\u003d \"Mayor\u0027s Office of Contracts\")).select(\"Agency\", \"Agency Name\").show()\n    df.where((col(\"Agency\")\u003d\u003d \"OMB\") \u0026 (col(\"Agency Name\") !\u003d \"Office of Management and Budget\")).select(\"Agency\", \"Agency Name\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nagency_incorrect_display(df)"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef agency_name_correction(df):\n\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"NYPD\"),\"New York City Police Department\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"HPD\"),\"Department of Housing Preservation and Development\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DOT\"),\"Department of Transportation\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DSNY\"),\"Department of Sanitation\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DEP\"),\"Department of Environmental Protection\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DOB\"),\"Department of Buildings\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DPR\"),\"Department of Parks and Recreation\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DOHMH\"),\"Department of Health and Mental Hygiene\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DOF\"),\"Department of Finance\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"TLC\"),\"Taxi and Limouisine Commission\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DHS\"),\"Department of Homeless Services\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DCA\"),\"Department of Consumer Affairs\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"HRA\"),\"Human Resources Administration\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DFTA\"),\"Department for the Aging\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"MAYORâ€  S OFFICE OF SPECIAL ENFORCEMENT\"),\"Mayor\u0027s Office of Special Enforcement\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"EDC\"),\"Economic Development Corporation\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DOE\"),\"Department of Education\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"3-1-1\"),\"3-1-1 Call Center\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"NYCEM\"),\"NYC Emergency Management\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DOITT\"),\"Department of Information Technology and Telecommunications\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DCAS\"),\"Department of Citywide Administrative Services\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"ACS\"),\"Administration for Children\u0027s Service\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"TAX\"),\"Tax Commission\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DVS\"),\"Department of Veteran\u0027s Services\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DCP\"),\"Department of City Plannning\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"DORIS\"),\"Department of Records and Information Services\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"FDNY\"),\"Fire Department of New York\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"TAT\"),\"Tax Appeals Tribunal\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"COIB\"),\"Conflicts of Interest Board\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"CEO\"),\"Center for Economic Opportunity\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"MOC\"),\"Mayor\u0027s Office of Contracts\").otherwise(col(\"Agency Name\")))\n    df \u003d df.withColumn(\"Agency Name\", when((col(\"Agency\") \u003d\u003d \"OMB\"),\"Office of Management and Budget\").otherwise(col(\"Agency Name\")))\n    return df\n"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf\u003d agency_name_correction(df)"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nagency_incorrect_display(df)"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef complaint_outliers_display(df):\n    df.where((col(\"Complaint Type\").contains(\"Noise\")) \u0026 (col(\"Complaint Type\")!\u003d \"Noise Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"Ferry\")) \u0026 (col(\"Complaint Type\")!\u003d \"Ferry Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"Highway\")) \u0026 (col(\"Complaint Type\")!\u003d \"Highway Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"Taxi\")) \u0026 (col(\"Complaint Type\")!\u003d \"Taxi Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"Water\")) \u0026 (col(\"Complaint Type\")!\u003d \"Water Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"Parking\")) \u0026 (col(\"Complaint Type\")!\u003d \"Parking Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"Blocked Driveway\")) \u0026 (col(\"Complaint Type\")!\u003d \"Blocked Driveway Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"Street\")) \u0026 (col(\"Complaint Type\")!\u003d \"Street Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"Heating\")) \u0026 (col(\"Complaint Type\")!\u003d \"Heat Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"Plumbing\")) \u0026 (col(\"Complaint Type\")!\u003d \"Plumbing Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"unsanitary condition\")) \u0026 (col(\"Complaint Type\")!\u003d \"Unsanitary condition Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"construction\")) \u0026 (col(\"Complaint Type\")!\u003d \"Construction Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"traffic\")) \u0026 (col(\"Complaint Type\")!\u003d \"Traffic Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n    df.where((col(\"Complaint Type\").contains(\"sewer\")) \u0026 (col(\"Complaint Type\")!\u003d \"Sewer Complaint\")).select(\"Unique Key\", \"Complaint Type\").show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ncomplaint_outliers_display(df)"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef complaint_outliers_correction(df):\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"Noise.*\",\"Noise Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"Ferry.*\",\"Ferry Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"Highway.*\",\"Highway Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"Taxi.*\",\"Taxi Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"Water.*\",\"Water Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"Parking.*\",\"Parking Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"Blocked Driveway.*\",\"Blocked Driveway Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"Street.*\",\"Street Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"Heating.*\",\"Heating Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"Plumbing.*\",\"Plumbing Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"unsanitary condition.*\",\"Unsanitary condition Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"construction.*\",\"Construction Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"traffic.*\",\"Traffic Complaint\"))\n    df\u003ddf.withColumn(\"Complaint Type\", regexp_replace(col(\"Complaint Type\"),\"sewer.*\",\"Sewer Complaint\"))\n    return df"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf \u003d complaint_outliers_correction(df)"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ncomplaint_outliers_display(df)"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#this code will help us in eliminating the rows with missing borough/zip code values\n\ndf.createOrReplaceTempView(\"temp\")\ndf \u003dspark.sql(\"SELECT * FROM temp WHERE BOROUGH IN (\u0027QUEENS\u0027,\u0027BROOKLYN\u0027,\u0027BRONX\u0027,\u0027MANHATTAN\u0027,\u0027STATEN ISLAND\u0027)\")"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf.take(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndef null_vals(curr_val, null_val):\n\tnull_val.append(data.select([count(when((col(curr_val)\u003d\u003d\"NA\")|(col(curr_val)\u003d\u003d\"UNKNOWN\") | (col(curr_val)\u003d\u003d\"Unspecified\") | (col(curr_val)\u003d\u003d\"N/A\") | (col(curr_val)\u003d\u003d\"\") | (col(curr_val).isNull()) | (col(curr_val)\u003d\u003d\"0 Unspecified\"), curr_val))]).take(1)[0][0])\n\ndef drop_sparse_cols(df):\n    rows \u003d []\n\n    for i in df.columns:\n    \tnullValues(i, rows)\n\n    length \u003d df.count()\n    \n    for i in range(0, len(rows)):\n    \trows[i] \u003d (rows[i] / length) * 100\n\n    headers \u003d df.columns\n    \n    for i in range(0, len(rows)):\n\t    if(rows[i] \u003e 70):\n\t\t    df \u003d df.drop(headers[i])   "
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf.coalesce(1).write.option(\"header\", \"true\").csv(\"cleanData-311.csv\")"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndfCreation(flu_vac_df)\nflu_vac_df.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nFLU_ZIP_CODE \u003d \"ZIP Code\"\nFLU_PRIMARY_KEY \u003d \"OBJECTID\"\nFLU_BOROUGH \u003d \"Borough\"\nflu_vac_df \u003d stringtoI(flu_vac_df,FLU_ZIP_CODE)\nflu_vac_df.printSchema()\ninc_zipToB_map(flu_vac_df, FLU_ZIP_CODE, FLU_PRIMARY_KEY, FLU_BOROUGH)"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nNYPD_complaint_df.printSchema()\n\n# Validation !!!!\ndef show_dates_in_the_future(data_frame, date_col_name):\n    data_frame.where((col(date_col_name)\u003ecurrent_date())).select(date_col_name).show()\n    \nshow_dates_in_the_future(NYPD_complaint_df, \"CMPLNT_FR_DT\")\n\nshow_dates_in_the_future(NYPD_complaint_df, \"CMPLNT_TO_DT\")\n\nshow_dates_in_the_future(NYPD_complaint_df, \"RPT_DT\")\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nNYPD_complaint_df \u003d NYPD_complaint_df.drop(\u0027X_COORD_CD\u0027)\nNYPD_complaint_df \u003d NYPD_complaint_df.drop(\u0027Y_COORD_CD\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nNYPD_complaint_df \u003d NYPD_complaint_df.drop(\u0027Latitude\u0027)\nNYPD_complaint_df \u003d NYPD_complaint_df.drop(\u0027Longitude\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nNYPD_arrests_df.printSchema()\n\nshow_dates_in_the_future(NYPD_arrests_df, \"ARREST_DATE\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nNYPD_arrests_df \u003d NYPD_arrests_df.drop(\u0027X_COORD_CD\u0027)\nNYPD_arrests_df \u003d NYPD_arrests_df.drop(\u0027Y_COORD_CD\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nNYPD_arrests_df \u003d NYPD_arrests_df.drop(\u0027Latitude\u0027)\nNYPD_arrests_df \u003d NYPD_arrests_df.drop(\u0027Longitude\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nshooting_dataset_df.printSchema()\n\nshow_dates_in_the_future(NYPD_arrests_df, \"OCCUR_DATE\")"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n\nshooting_dataset_df \u003d shooting_dataset_df.drop(\u0027X_COORD_CD\u0027)\nshooting_dataset_df \u003d shooting_dataset_df.drop(\u0027Y_COORD_CD\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nshooting_dataset_df \u003d shooting_dataset_df.drop(\u0027Latitude\u0027)\nshooting_dataset_df \u003d shooting_dataset_df.drop(\u0027Longitude\u0027)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nbikes_building_df.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nbikes_building_df \u003d bikes_building_df.withColumn(\"TenantPostcode\", bikes_building_df[\"TenantPostcode\"].cast(IntegerType(\nbikes_building_df \u003d bikes_building_df.withColumn(\"OwnerZipCode\", bikes_building_df[\"OwnerZipCode\"].cast(IntegerType())) "
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nrdd \u003d bikes_building_df.rdd                               \ndf \u003d spark.createDataFrame(rdd, bikes_building_df.schema) "
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"Incorrect Data for BRONX:\\n\")                                                                                                            \ndf.where((col(\"TenantPostcode\") \u003e 10450) \u0026 (col(\"TenantPostcode\") \u003c 10475) \u0026 (col(\"TenantBorough\") !\u003d \"BRONX\")).select(\"TenantBorough\").show()  \nprint(\"Incorrect Data for BROOKLYN:\\n\")                                                                                                         \ndf.where((col(\"TenantPostcode\") \u003e 11200) \u0026 (col(\"TenantPostcode\") \u003c 11240) \u0026 (col(\"TenantBorough\") !\u003d \"BROOKLYN\")).select(\"TenantBorough\").show(\nprint(\"Incorrect Data for MANHATTAN:\\n\")                                                                                                        \ndf.where((col(\"TenantPostcode\") \u003e 10000) \u0026 (col(\"TenantPostcode\") \u003c 10280) \u0026 (col(\"TenantBorough\") !\u003d \"MANHATTAN\")).select(\"TenantBorough\").show\nprint(\"Incorrect Data for STATEN ISLAND:\\n\")                                                                                                    \ndf.where((col(\"TenantPostcode\") \u003e 10300) \u0026 (col(\"TenantPostcode\") \u003c 10315) \u0026 (col(\"TenantBorough\") !\u003d \"STATEN ISLAND\")).select(\"TenantBorough\").\nprint(\"Incorrect Data for QUEENS:\\n\")                                                                                                           \ndf.where((col(\"TenantPostcode\") \u003e 11350) \u0026 (col(\"TenantPostcode\") \u003c 11700) \u0026 (col(\"TenantBorough\") !\u003d \"QUEENS\")).select(\"TenantBorough\").show() "
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.withColumn(\"TenantBorough\", when((col(\n            .when((col(\"TenantPostcode\") \u003e 112\n            .when((col(\"TenantPostcode\")\u003e10450\n            .when((col(\"TenantPostcode\")\u003e10000\n            .when((col(\"TenantPostcode\")\u003e10300\n            .otherwise(col(\"TenantBorough\"))) "
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"Incorrect Data for BRONX:\\n\")                                                                                                           \ndf.where((col(\"TenantPostcode\") \u003e 10450) \u0026 (col(\"TenantPostcode\") \u003c 10475) \u0026 (col(\"TenantBorough\") !\u003d \"BRONX\")).select(\"TenantBorough\").show() \nprint(\"Incorrect Data for BROOKLYN:\\n\")                                                                                                        \ndf.where((col(\"TenantPostcode\") \u003e 11200) \u0026 (col(\"TenantPostcode\") \u003c 11240) \u0026 (col(\"TenantBorough\") !\u003d \"BROOKLYN\")).select(\"TenantBorough\").show\nprint(\"Incorrect Data for MANHATTAN:\\n\")                                                                                                       \ndf.where((col(\"TenantPostcode\") \u003e 10000) \u0026 (col(\"TenantPostcode\") \u003c 10280) \u0026 (col(\"TenantBorough\") !\u003d \"MANHATTAN\")).select(\"TenantBorough\").sho\nprint(\"Incorrect Data for STATEN ISLAND:\\n\")                                                                                                   \ndf.where((col(\"TenantPostcode\") \u003e 10300) \u0026 (col(\"TenantPostcode\") \u003c 10315) \u0026 (col(\"TenantBorough\") !\u003d \"STATEN ISLAND\")).select(\"TenantBorough\")\nprint(\"Incorrect Data for QUEENS:\\n\")                                                                                                          \ndf.where((col(\"TenantPostcode\") \u003e 11350) \u0026 (col(\"TenantPostcode\") \u003c 11700) \u0026 (col(\"TenantBorough\") !\u003d \"QUEENS\")).select(\"TenantBorough\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"Missing city data:\\n\")                                                                                                                \ndf.where((col(\"TenantCity\") \u003d\u003d\"N/A\") | (col(\"TenantCity\")\u003d\u003d\"NA\") | (col(\"TenantCity\").isNull())).select(\"TenantBorough\", \"TenantCity\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.withColumn(\"TenantCity\", when((col(\"T\n            .otherwise(col(\"TenantBorough\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"Missing city data:\\n\")                                                                                                                 \ndf.where((col(\"TenantCity\") \u003d\u003d\"N/A\") | (col(\"TenantCity\")\u003d\u003d\"NA\") | (col(\"TenantCity\").isNull())).select(\"TenantBorough\", \"TenantCity\").show() "
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"For DateofRequest :\")                                                    \ndf.where((col(\"DateofRequest\")\u003ecurrent_date())).select(\"DateofRequest\").show()  \nprint(\"For DateOfBuilding :\")                                                   \ndf.where((col(\"DateOfBuilding\")\u003ecurrent_date())).select(\"DateOfBuilding\").show()\nprint(\"For DateOfElevator :\")                                                   \ndf.where((col(\"DateOfElevator\")\u003ecurrent_date())).select(\"DateOfElevator\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.filter(df[\"DateofRequest\"] \u003c\u003d current_date())  \ndf \u003d df.filter(df[\"DateOfBuilding\"] \u003c\u003d current_date()) \ndf \u003d df.filter(df[\"DateOfElevator\"] \u003c\u003d current_date()) "
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nNYPD_B_summons_df.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nrdd \u003d NYPD_B_summons_df.rdd\ndf \u003d spark.createDataFrame(rdd, NYPD_B_summons_df.schema)"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"Missing city data:\\n\")\ndf.where((col(\"CITY_NM\") \u003d\u003d\"N/A\") | (col(\"CITY_NM\")\u003d\u003d\"NA\") | (col(\"CITY_NM\").isNull())).select(\"CITY_NM\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.withColumn(\"CITY_NM\", when((col(\"CITY_NM\").isNull()) | (col(\"CITY_NM\")\u003d\u003d\"N/A\") | (col(\"CITY_NM\")\u003d\u003d\"NA\"),\"New York\")\n            .otherwise(col(\"CITY_NM\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"Missing city data:\\n\")\ndf.where((col(\"CITY_NM\") \u003d\u003d\"N/A\") | (col(\"CITY_NM\")\u003d\u003d\"NA\") | (col(\"CITY_NM\").isNull())).select(\"CITY_NM\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf.where((col(\"VIOLATION_DATE\")\u003ecurrent_date())).select(\"VIOLATION_DATE\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.filter(df[\"VIOLATION_DATE\"] \u003c\u003d current_date())"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.drop(\u0027X_COORD_CD\u0027)\ndf \u003d df.drop(\u0027Y_COORD_CD\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.drop(\u0027Latitude\u0027)\ndf \u003d df.drop(\u0027Longitude\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nwifi_df.printSchema()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nwifi_df \u003d wifi_df.withColumn(\"Postcode\", wifi_df[\"Postcode\"].cast(IntegerType()))"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nrdd \u003d wifi_df.rdd\ndf \u003d spark.createDataFrame(rdd, wifi_df.schema)"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"Incorrect Data for BRONX:\\n\")\ndf.where((col(\"Postcode\") \u003e 10450) \u0026 (col(\"Postcode\") \u003c 10475) \u0026 (col(\"Borough Name\") !\u003d \"Bronx\")).select(\"Borough Name\").show()\nprint(\"Incorrect Data for BROOKLYN:\\n\")\ndf.where((col(\"Postcode\") \u003e 11200) \u0026 (col(\"Postcode\") \u003c 11240) \u0026 (col(\"Borough Name\") !\u003d \"Brooklyn\")).select(\"Borough Name\").show()\nprint(\"Incorrect Data for MANHATTAN:\\n\")\ndf.where((col(\"Postcode\") \u003e 10000) \u0026 (col(\"Postcode\") \u003c 10280) \u0026 (col(\"Borough Name\") !\u003d \"Manhattan\")).select(\"Borough Name\").show()\nprint(\"Incorrect Data for STATEN ISLAND:\\n\")\ndf.where((col(\"Postcode\") \u003e 10300) \u0026 (col(\"Postcode\") \u003c 10315) \u0026 (col(\"Borough Name\") !\u003d \"Staten Island\")).select(\"Borough Name\").show()\nprint(\"Incorrect Data for QUEENS:\\n\")\ndf.where((col(\"Postcode\") \u003e 11350) \u0026 (col(\"Postcode\") \u003c 11700) \u0026 (col(\"Borough Name\") !\u003d \"Queens\")).select(\"Borough Name\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.withColumn(\"Borough\", when((col(\"Postcode\") \u003e 11350) \u0026 (col(\"Postcode\")\u003c11700),\"Queens\")\n            .when((col(\"Postcode\") \u003e 11200) \u0026 (col(\"Postcode\")\u003c11240),\"Brooklyn\")\n            .when((col(\"Postcode\")\u003e10450) \u0026 (col(\"Postcode\")\u003c10475),\"Bronx\")\n            .when((col(\"Postcode\")\u003e10000) \u0026 (col(\"Postcode\")\u003c10280),\"Manhattan\")\n            .when((col(\"Postcode\")\u003e10300) \u0026 (col(\"Postcode\")\u003c10315),\"Staten Island\")\n            .otherwise(col(\"Borough\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"Incorrect Data for BRONX:\\n\")\ndf.where((col(\"Postcode\") \u003e 10450) \u0026 (col(\"Postcode\") \u003c 10475) \u0026 (col(\"Borough Name\") !\u003d \"Bronx\")).select(\"Borough Name\").show()\nprint(\"Incorrect Data for BROOKLYN:\\n\")\ndf.where((col(\"Postcode\") \u003e 11200) \u0026 (col(\"Postcode\") \u003c 11240) \u0026 (col(\"Borough Name\") !\u003d \"Brooklyn\")).select(\"Borough Name\").show()\nprint(\"Incorrect Data for MANHATTAN:\\n\")\ndf.where((col(\"Postcode\") \u003e 10000) \u0026 (col(\"Postcode\") \u003c 10280) \u0026 (col(\"Borough Name\") !\u003d \"Manhattan\")).select(\"Borough Name\").show()\nprint(\"Incorrect Data for STATEN ISLAND:\\n\")\ndf.where((col(\"Postcode\") \u003e 10300) \u0026 (col(\"Postcode\") \u003c 10315) \u0026 (col(\"Borough Name\") !\u003d \"Staten Island\")).select(\"Borough Name\").show()\nprint(\"Incorrect Data for QUEENS:\\n\")\ndf.where((col(\"Postcode\") \u003e 11350) \u0026 (col(\"Postcode\") \u003c 11700) \u0026 (col(\"Borough Name\") !\u003d \"Queens\")).select(\"Borough Name\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"Missing city data:\\n\")\ndf.where((col(\"City\") \u003d\u003d\"N/A\") | (col(\"City\")\u003d\u003d\"NA\") | (col(\"City\").isNull())).select(\"City\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.withColumn(\"City\", when((col(\"City\").isNull()) | (col(\"City\")\u003d\u003d\"N/A\") | (col(\"City\")\u003d\u003d\"NA\"),\"New York\")\n            .otherwise(col(\"City\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"Missing city data:\\n\")\ndf.where((col(\"City\") \u003d\u003d\"N/A\") | (col(\"City\")\u003d\u003d\"NA\") | (col(\"City\").isNull())).select(\"City\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf.where((col(\"Created Date\") \u003e current_date())).select(\"Created Date\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.drop(\u0027X\u0027)\ndf \u003d df.drop(\u0027Y\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nhousing_buildings_df.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nhousing_buildings_df \u003d housing_buildings_df.withColumn(\"Postcode\", housing_buildings_df[\"Postcode\"].cast(IntegerType()))"
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nrdd \u003d housing_buildings_df.rdd\ndf \u003d spark.createDataFrame(rdd, housing_buildings_df.schema)"
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"Incorrect Data for BRONX:\\n\")\ndf.where((col(\"Postcode\") \u003e 10450) \u0026 (col(\"Postcode\") \u003c 10475) \u0026 (col(\"Borough\") !\u003d \"Bronx\")).select(\"Borough\").show()\nprint(\"Incorrect Data for BROOKLYN:\\n\")\ndf.where((col(\"Postcode\") \u003e 11200) \u0026 (col(\"Postcode\") \u003c 11240) \u0026 (col(\"Borough\") !\u003d \"Brooklyn\")).select(\"Borough\").show()\nprint(\"Incorrect Data for MANHATTAN:\\n\")\ndf.where((col(\"Postcode\") \u003e 10000) \u0026 (col(\"Postcode\") \u003c 10280) \u0026 (col(\"Borough\") !\u003d \"Manhattan\")).select(\"Borough\").show()\nprint(\"Incorrect Data for STATEN ISLAND:\\n\")\ndf.where((col(\"Postcode\") \u003e 10300) \u0026 (col(\"Postcode\") \u003c 10315) \u0026 (col(\"Borough\") !\u003d \"Staten Island\")).select(\"Borough\").show()\nprint(\"Incorrect Data for QUEENS:\\n\")\ndf.where((col(\"Postcode\") \u003e 11350) \u0026 (col(\"Postcode\") \u003c 11700) \u0026 (col(\"Borough\") !\u003d \"Queens\")).select(\"Borough\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.withColumn(\"Borough\", when((col(\"Postcode\") \u003e 11350) \u0026 (col(\"Postcode\")\u003c11700),\"Queens\")\n            .when((col(\"Postcode\") \u003e 11200) \u0026 (col(\"Postcode\")\u003c11240),\"Brooklyn\")\n            .when((col(\"Postcode\")\u003e10450) \u0026 (col(\"Postcode\")\u003c10475),\"Bronx\")\n            .when((col(\"Postcode\")\u003e10000) \u0026 (col(\"Postcode\")\u003c10280),\"Manhattan\")\n            .when((col(\"Postcode\")\u003e10300) \u0026 (col(\"Postcode\")\u003c10315),\"Staten Island\")\n            .otherwise(col(\"Borough\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(\"Incorrect Data for BRONX:\\n\")\ndf.where((col(\"Postcode\") \u003e 10450) \u0026 (col(\"Postcode\") \u003c 10475) \u0026 (col(\"Borough\") !\u003d \"Bronx\")).select(\"Borough\").show()\nprint(\"Incorrect Data for BROOKLYN:\\n\")\ndf.where((col(\"Postcode\") \u003e 11200) \u0026 (col(\"Postcode\") \u003c 11240) \u0026 (col(\"Borough\") !\u003d \"Brooklyn\")).select(\"Borough\").show()\nprint(\"Incorrect Data for MANHATTAN:\\n\")\ndf.where((col(\"Postcode\") \u003e 10000) \u0026 (col(\"Postcode\") \u003c 10280) \u0026 (col(\"Borough\") !\u003d \"Manhattan\")).select(\"Borough\").show()\nprint(\"Incorrect Data for STATEN ISLAND:\\n\")\ndf.where((col(\"Postcode\") \u003e 10300) \u0026 (col(\"Postcode\") \u003c 10315) \u0026 (col(\"Borough\") !\u003d \"Staten Island\")).select(\"Borough\").show()\nprint(\"Incorrect Data for QUEENS:\\n\")\ndf.where((col(\"Postcode\") \u003e 11350) \u0026 (col(\"Postcode\") \u003c 11700) \u0026 (col(\"Borough\") !\u003d \"Queens\")).select(\"Borough\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf.where((col(\"Project Start Date\")\u003ecurrent_date())).select(\"Project Start Date\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d df.filter(df[\"Project Start Date\"] \u003c\u003d current_date())\n"
    }
  ]
}