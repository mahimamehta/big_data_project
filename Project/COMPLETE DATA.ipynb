{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "005fb918",
   "metadata": {},
   "source": [
    "<h2>Assignment 3 - Big Data - Group 8<h2>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d3862",
   "metadata": {},
   "source": [
    "<b>Dataset - 311 Service Requests from 2010 to Present<br></b>\n",
    "<b>Team Members</b> - <br>Amani Deepthi Matta (am10620)<br>\n",
    "               Denys Fenchenko (df1911)<br>\n",
    "                Mahima Mehta (mm11527)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7c74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import humanfriendly\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82805d34",
   "metadata": {},
   "source": [
    "We will be using openclean for data profiling and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af48c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.data.source.socrata import Socrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b9938ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using '311 Service Requests from 2010 to Present' in file ./erm2-nwe9.tsv.gz of size 730.96 MB\n"
     ]
    }
   ],
   "source": [
    "dataset = Socrata().dataset('erm2-nwe9')\n",
    "\n",
    "#datafile = './data/erm2-nwe9.tsv.gz'\n",
    "\n",
    "# Remove the comment for this line if you want to use the full dataset.\n",
    "datafile = './erm2-nwe9.tsv.gz'\n",
    "\n",
    "\n",
    "# Download file only if it does not exist already.\n",
    "if not os.path.isfile(datafile):\n",
    "    with gzip.open(datafile, 'wb') as f:\n",
    "        print('Downloading ...\\n')\n",
    "        dataset.write(f)\n",
    "\n",
    "\n",
    "fsize = humanfriendly.format_size(os.stat(datafile).st_size)\n",
    "print(\"Using '{}' in file {} of size {}\".format(dataset.name, datafile, fsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb61d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the size of the full dataset file, we make use of openclean's\n",
    "# stream operator to avoid having to load the dataset into main-memory.\n",
    "\n",
    "from openclean.pipeline import stream\n",
    "\n",
    "ds_full = stream(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b5a941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,475,853 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique Key</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Closed Date</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Agency Name</th>\n",
       "      <th>Complaint Type</th>\n",
       "      <th>Descriptor</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>Incident Zip</th>\n",
       "      <th>Incident Address</th>\n",
       "      <th>...</th>\n",
       "      <th>Vehicle Type</th>\n",
       "      <th>Taxi Company Borough</th>\n",
       "      <th>Taxi Pick Up Location</th>\n",
       "      <th>Bridge Highway Name</th>\n",
       "      <th>Bridge Highway Direction</th>\n",
       "      <th>Road Ramp</th>\n",
       "      <th>Bridge Highway Segment</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41848614</td>\n",
       "      <td>03/01/2019 08:51:00 AM</td>\n",
       "      <td>03/01/2019 10:06:00 PM</td>\n",
       "      <td>DOT</td>\n",
       "      <td>Department of Transportation</td>\n",
       "      <td>Street Condition</td>\n",
       "      <td>Pothole</td>\n",
       "      <td></td>\n",
       "      <td>11106</td>\n",
       "      <td>31-10 36 AVENUE</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.756492111039634</td>\n",
       "      <td>-73.92958204996667</td>\n",
       "      <td>(40.756492111039634, -73.92958204996667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41848615</td>\n",
       "      <td>03/01/2019 03:02:00 PM</td>\n",
       "      <td>03/03/2019 12:00:00 AM</td>\n",
       "      <td>DSNY</td>\n",
       "      <td>Department of Sanitation</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Sidewalk</td>\n",
       "      <td>10314</td>\n",
       "      <td>1749 VICTORY BOULEVARD</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.61312795235816</td>\n",
       "      <td>-74.12198440400978</td>\n",
       "      <td>(40.61312795235816, -74.12198440400978)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41848616</td>\n",
       "      <td>03/01/2019 02:32:00 PM</td>\n",
       "      <td>03/03/2019 12:00:00 AM</td>\n",
       "      <td>DSNY</td>\n",
       "      <td>Department of Sanitation</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Sidewalk</td>\n",
       "      <td>11231</td>\n",
       "      <td>251 PRESIDENT STREET</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.68197142551911</td>\n",
       "      <td>-73.99704711433336</td>\n",
       "      <td>(40.68197142551911, -73.99704711433336)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41848617</td>\n",
       "      <td>03/01/2019 01:48:00 PM</td>\n",
       "      <td>03/07/2019 12:00:00 AM</td>\n",
       "      <td>DSNY</td>\n",
       "      <td>Department of Sanitation</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Sidewalk</td>\n",
       "      <td>11378</td>\n",
       "      <td>58-18 57 DRIVE</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.72165672120027</td>\n",
       "      <td>-73.91119832164968</td>\n",
       "      <td>(40.72165672120027, -73.91119832164968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41848618</td>\n",
       "      <td>03/01/2019 12:15:00 PM</td>\n",
       "      <td>03/07/2019 12:00:00 AM</td>\n",
       "      <td>DSNY</td>\n",
       "      <td>Department of Sanitation</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Sidewalk</td>\n",
       "      <td>11691</td>\n",
       "      <td>15-20 DUNBAR STREET</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.6120650341309</td>\n",
       "      <td>-73.7672793933339</td>\n",
       "      <td>(40.6120650341309, -73.7672793933339)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41848619</td>\n",
       "      <td>03/01/2019 11:39:00 AM</td>\n",
       "      <td>03/06/2019 12:00:00 AM</td>\n",
       "      <td>DSNY</td>\n",
       "      <td>Department of Sanitation</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Sidewalk</td>\n",
       "      <td>10465</td>\n",
       "      <td>1022 THROGGMORTON AVENUE</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.83377075997836</td>\n",
       "      <td>-73.8211107319425</td>\n",
       "      <td>(40.83377075997836, -73.8211107319425)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41848620</td>\n",
       "      <td>03/01/2019 10:13:00 AM</td>\n",
       "      <td>03/06/2019 12:00:00 AM</td>\n",
       "      <td>DSNY</td>\n",
       "      <td>Department of Sanitation</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Sidewalk</td>\n",
       "      <td>11203</td>\n",
       "      <td>5018 SNYDER AVENUE</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.650116182789304</td>\n",
       "      <td>-73.92992496632176</td>\n",
       "      <td>(40.650116182789304, -73.92992496632176)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41848621</td>\n",
       "      <td>03/01/2019 07:10:00 AM</td>\n",
       "      <td>03/06/2019 12:00:00 AM</td>\n",
       "      <td>DSNY</td>\n",
       "      <td>Department of Sanitation</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Request Large Bulky Item Collection</td>\n",
       "      <td>Sidewalk</td>\n",
       "      <td>11357</td>\n",
       "      <td>21-02 147 STREET</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.78008910887591</td>\n",
       "      <td>-73.81920401853289</td>\n",
       "      <td>(40.78008910887591, -73.81920401853289)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41848623</td>\n",
       "      <td>03/01/2019 03:38:16 PM</td>\n",
       "      <td>03/11/2019 12:27:45 PM</td>\n",
       "      <td>DOT</td>\n",
       "      <td>Department of Transportation</td>\n",
       "      <td>Broken Parking Meter</td>\n",
       "      <td>No Receipt</td>\n",
       "      <td>Street</td>\n",
       "      <td>10040</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.86357250126242</td>\n",
       "      <td>-73.92601241651245</td>\n",
       "      <td>(40.86357250126242, -73.92601241651245)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28373736</td>\n",
       "      <td>06/30/2014 12:17:52 PM</td>\n",
       "      <td>06/30/2014 12:18:40 PM</td>\n",
       "      <td>HRA</td>\n",
       "      <td>HRA Benefit Card Replacement</td>\n",
       "      <td>Benefit Card Replacement</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>NYC Street Address</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unique Key            Created Date             Closed Date Agency  \\\n",
       "0   41848614  03/01/2019 08:51:00 AM  03/01/2019 10:06:00 PM    DOT   \n",
       "1   41848615  03/01/2019 03:02:00 PM  03/03/2019 12:00:00 AM   DSNY   \n",
       "2   41848616  03/01/2019 02:32:00 PM  03/03/2019 12:00:00 AM   DSNY   \n",
       "3   41848617  03/01/2019 01:48:00 PM  03/07/2019 12:00:00 AM   DSNY   \n",
       "4   41848618  03/01/2019 12:15:00 PM  03/07/2019 12:00:00 AM   DSNY   \n",
       "5   41848619  03/01/2019 11:39:00 AM  03/06/2019 12:00:00 AM   DSNY   \n",
       "6   41848620  03/01/2019 10:13:00 AM  03/06/2019 12:00:00 AM   DSNY   \n",
       "7   41848621  03/01/2019 07:10:00 AM  03/06/2019 12:00:00 AM   DSNY   \n",
       "8   41848623  03/01/2019 03:38:16 PM  03/11/2019 12:27:45 PM    DOT   \n",
       "9   28373736  06/30/2014 12:17:52 PM  06/30/2014 12:18:40 PM    HRA   \n",
       "\n",
       "                    Agency Name                       Complaint Type  \\\n",
       "0  Department of Transportation                     Street Condition   \n",
       "1      Department of Sanitation  Request Large Bulky Item Collection   \n",
       "2      Department of Sanitation  Request Large Bulky Item Collection   \n",
       "3      Department of Sanitation  Request Large Bulky Item Collection   \n",
       "4      Department of Sanitation  Request Large Bulky Item Collection   \n",
       "5      Department of Sanitation  Request Large Bulky Item Collection   \n",
       "6      Department of Sanitation  Request Large Bulky Item Collection   \n",
       "7      Department of Sanitation  Request Large Bulky Item Collection   \n",
       "8  Department of Transportation                 Broken Parking Meter   \n",
       "9  HRA Benefit Card Replacement             Benefit Card Replacement   \n",
       "\n",
       "                            Descriptor       Location Type Incident Zip  \\\n",
       "0                              Pothole                            11106   \n",
       "1  Request Large Bulky Item Collection            Sidewalk        10314   \n",
       "2  Request Large Bulky Item Collection            Sidewalk        11231   \n",
       "3  Request Large Bulky Item Collection            Sidewalk        11378   \n",
       "4  Request Large Bulky Item Collection            Sidewalk        11691   \n",
       "5  Request Large Bulky Item Collection            Sidewalk        10465   \n",
       "6  Request Large Bulky Item Collection            Sidewalk        11203   \n",
       "7  Request Large Bulky Item Collection            Sidewalk        11357   \n",
       "8                           No Receipt              Street        10040   \n",
       "9                             Medicaid  NYC Street Address                \n",
       "\n",
       "           Incident Address  ... Vehicle Type Taxi Company Borough  \\\n",
       "0           31-10 36 AVENUE  ...                                     \n",
       "1    1749 VICTORY BOULEVARD  ...                                     \n",
       "2      251 PRESIDENT STREET  ...                                     \n",
       "3            58-18 57 DRIVE  ...                                     \n",
       "4       15-20 DUNBAR STREET  ...                                     \n",
       "5  1022 THROGGMORTON AVENUE  ...                                     \n",
       "6        5018 SNYDER AVENUE  ...                                     \n",
       "7          21-02 147 STREET  ...                                     \n",
       "8                            ...                                     \n",
       "9                            ...                                     \n",
       "\n",
       "  Taxi Pick Up Location Bridge Highway Name Bridge Highway Direction  \\\n",
       "0                                                                      \n",
       "1                                                                      \n",
       "2                                                                      \n",
       "3                                                                      \n",
       "4                                                                      \n",
       "5                                                                      \n",
       "6                                                                      \n",
       "7                                                                      \n",
       "8                                                                      \n",
       "9                                                                      \n",
       "\n",
       "  Road Ramp Bridge Highway Segment            Latitude           Longitude  \\\n",
       "0                                   40.756492111039634  -73.92958204996667   \n",
       "1                                    40.61312795235816  -74.12198440400978   \n",
       "2                                    40.68197142551911  -73.99704711433336   \n",
       "3                                    40.72165672120027  -73.91119832164968   \n",
       "4                                     40.6120650341309   -73.7672793933339   \n",
       "5                                    40.83377075997836   -73.8211107319425   \n",
       "6                                   40.650116182789304  -73.92992496632176   \n",
       "7                                    40.78008910887591  -73.81920401853289   \n",
       "8                                    40.86357250126242  -73.92601241651245   \n",
       "9                                                                            \n",
       "\n",
       "                                   Location  \n",
       "0  (40.756492111039634, -73.92958204996667)  \n",
       "1   (40.61312795235816, -74.12198440400978)  \n",
       "2   (40.68197142551911, -73.99704711433336)  \n",
       "3   (40.72165672120027, -73.91119832164968)  \n",
       "4     (40.6120650341309, -73.7672793933339)  \n",
       "5    (40.83377075997836, -73.8211107319425)  \n",
       "6  (40.650116182789304, -73.92992496632176)  \n",
       "7   (40.78008910887591, -73.81920401853289)  \n",
       "8   (40.86357250126242, -73.92601241651245)  \n",
       "9                                            \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of records in the datasets.\n",
    "\n",
    "print(f'{ds_full.count():,} rows.')\n",
    "\n",
    "\n",
    "# Print the first ten rows of the dataset to get a first\n",
    "# idea of the content.\n",
    "\n",
    "ds_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb0aeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view on columns in the dataset.\n",
    "\n",
    "COLUMNS = [\n",
    "    'Unique Key',\n",
    "    'Created Date',\n",
    "    'Closed Date',\n",
    "    'Agency',\n",
    "    'Agency Name',\n",
    "    'Complaint Type',\n",
    "    'Descriptor',\n",
    "    'Location Type',\n",
    "    'Incident Zip',\n",
    "    'Incident Address',\n",
    "    'Street Name',\n",
    "    'Cross Street 1',\n",
    "    'Cross Street 2',\n",
    "    'Intersection Street 1',\n",
    "    'Intersection Street 2',\n",
    "    'Address Type',\n",
    "    'City',\n",
    "    'Landmark',\n",
    "    'Facility Type',\n",
    "    'Status',\n",
    "    'Due Date',\n",
    "    'Resolution Description',\n",
    "    'Resolution Action Updated Date',\n",
    "    'Community Board',\n",
    "    'BBL',\n",
    "    'Borough',\n",
    "    'X Coordinate (State Plane)',\n",
    "    'Y Coordinate (State Plane)',\n",
    "    'Open Data Channel Type',\n",
    "    'Park Facility Name',\n",
    "    'Park Borough',\n",
    "    'Vehicle Type',\n",
    "    'Taxi Company Borough',\n",
    "    'Taxi Pick Up Location',\n",
    "    'Bridge Highway Name',\n",
    "    'Bridge Highway Direction',\n",
    "    'Road Ramp',\n",
    "    'Bridge Highway Segment',\n",
    "    'Latitude',\n",
    "    'Longitude',\n",
    "    'Location'\n",
    "]\n",
    "\n",
    "ds = ds_full.select(columns=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62914ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openclean.data.source.socrata.SODADataset"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a197f82b",
   "metadata": {},
   "source": [
    "# Data Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64895a0a",
   "metadata": {},
   "source": [
    "As a first step, we are profiling the data to get an insight of how the data looks.\n",
    "We will be using openclean for data profiling in order to use existing libraries for getting data stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b451e94",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n4/fwkpr4nx1hzbx2dwqjk68mkm0000gn/T/ipykernel_81281/3602029167.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenclean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultColumnProfiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprofiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_profiler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDefaultColumnProfiler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Print overview of profiling results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openclean/pipeline.py\u001b[0m in \u001b[0;36mprofile\u001b[0;34m(self, profilers, default_profiler)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mdefault_profiler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_profiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         )\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mColumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDatasetSchema\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataPipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openclean/pipeline.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0many\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \"\"\"\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openclean/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                     \u001b[0mconsumer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrowid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openclean/operator/stream/consumer.py\u001b[0m in \u001b[0;36mconsume\u001b[0;34m(self, rowid, row)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \"\"\"\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrowid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openclean/operator/stream/consumer.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, rowid, row)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openclean/operator/transform/select.py\u001b[0m in \u001b[0;36mstreamfunc\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstreamfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataRow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataRow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;34m\"\"\"Include only columns in the select clause.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolidxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mStreamFunctionHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstreamfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openclean/operator/transform/select.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstreamfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataRow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataRow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;34m\"\"\"Include only columns in the select clause.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolidxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mStreamFunctionHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstreamfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from openclean.profiling.column import DefaultColumnProfiler\n",
    "\n",
    "profiles = ds.profile(default_profiler=DefaultColumnProfiler)\n",
    "\n",
    "# Print overview of profiling results.\n",
    "\n",
    "profiles.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ed324",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the most frequent data type for each column.\n",
    "\n",
    "print('Schema\\n------')\n",
    "for col in ds.columns:\n",
    "    p = profiles.column(col)\n",
    "    print(\"  '{}' ({})\".format(col, p['datatypes']['distinct'].most_common(1)[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the minimum and maximum value for column 'Created Date'\n",
    "\n",
    "profiles.minmax('Created Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b55cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the minimum and maximum value for column 'Vehicle Year'\n",
    "\n",
    "profiles.minmax('Closed Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e33386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the most frequent values in column 'Ticket Time'\n",
    "\n",
    "profiles.column('Created Date').split(\" \",1).get('topValues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e486f8ca",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Data Standardization</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb120e2",
   "metadata": {},
   "source": [
    "<b>Approach 1 : Key Collision Clustering</b>\n",
    "\n",
    "openclean provides functionality for grouping values based on similarity. This functionality is adopted from OpenRefine Clustering. The main idea is to identify clusters of values that are different but might be alternative representations of the same thing.\n",
    "\n",
    "One clustering algorithm that is included in openclean is key collision clustering. The main idea of key collision methods is to create an alternative representation for each value (i.e., a key), and then group values based on their keys. The default key generator on openclean is the fingerprint that was adopted from OpenRefine. The main steps in creating a fingerprint key value are:\n",
    "\n",
    "- remove leading and trailing whitespace,\n",
    "- convert string to lower case,\n",
    "- Normalize string by removing punctuation and control characters and replacing non-diacritic characters (if the default normalizer is used),\n",
    "- Tokenize string by splitting on whitespace characters,\n",
    "- Sort the tokens and remove duplicates,\n",
    "- Concatenate remaining (sorted) tokens using a single space character as the delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7cbb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster agencies using 'Key Collision' clustering with the\n",
    "# default fingerprint key generator.\n",
    "\n",
    "from openclean.cluster.key import KeyCollision\n",
    "from openclean.function.value.key.fingerprint import Fingerprint\n",
    "\n",
    "agencies = stream(datafile).update('Agency', str.upper).distinct('Agency')\n",
    "clusters = KeyCollision(func=Fingerprint()).clusters(agencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08240d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple helper method to print the k largest clusters.\n",
    "\n",
    "def print_k_clusters(clusters, k=5):\n",
    "    clusters = sorted(clusters, key=lambda x: len(x), reverse=True)\n",
    "    val_count = sum([len(c) for c in clusters])\n",
    "    print('Total number of clusters is {} with {} values'.format(len(clusters), val_count))\n",
    "    for i in range(min(k, len(clusters))):\n",
    "        print('\\nCluster {}'.format(i + 1))\n",
    "        for key, cnt in clusters[i].items():\n",
    "            if key == '':\n",
    "                key = \"''\"\n",
    "            print(f'  {key} (x {cnt})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06eef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_k_clusters(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b5fad",
   "metadata": {},
   "source": [
    "<h6> Finding 1 </h6>\n",
    "Since all the values in Agency column have similar format, as a result there are no clusters formed.\n",
    "Hence we can say that data is already standardized for agency column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770ece4c",
   "metadata": {},
   "source": [
    "**Standardization of Street Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b15fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster street names using 'Key Collision' clustering with the\n",
    "# default fingerprint key generator.\n",
    "\n",
    "from openclean.cluster.key import KeyCollision\n",
    "from openclean.function.value.key.fingerprint import Fingerprint\n",
    "\n",
    "street_names = stream(datafile).update('Street Name', str.upper).distinct('Street Name')\n",
    "clusters = KeyCollision(func=Fingerprint()).clusters(street_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab86576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple helper method to print the k largest clusters.\n",
    "\n",
    "def print_k_clusters(clusters, k=5):\n",
    "    clusters = sorted(clusters, key=lambda x: len(x), reverse=True)\n",
    "    val_count = sum([len(c) for c in clusters])\n",
    "    print('Total number of clusters is {} with {} values'.format(len(clusters), val_count))\n",
    "    for i in range(min(k, len(clusters))):\n",
    "        print('\\nCluster {}'.format(i + 1))\n",
    "        for key, cnt in clusters[i].items():\n",
    "            if key == '':\n",
    "                key = \"''\"\n",
    "            print(f'  {key} (x {cnt})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaa66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_k_clusters(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a44b14",
   "metadata": {},
   "source": [
    "<h5>Finding 2</h5> \n",
    "Since there are different ways to write description of a particular street, so stanadarization on Street Name column forms many clusters. We are just printing 5 clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66e522",
   "metadata": {},
   "source": [
    "<h5>Specialized Key Generators</h5>\n",
    "\n",
    "The example shows that the default fingerprint key generator already provides some promising results. The method, however, misses many cases that we found are common in U.S. street address columns. A few examples are:\n",
    "\n",
    "Different abbreviations for street types, e.g., 125 St vs. 125 Str vs. 125 Street.\n",
    "Missing whitespace between street number and street type, e.g, 125St vs. 125 St.\n",
    "Text representations of street numbers, e.g., Fifth Ave vs. 5th Ave vs. 5 Ave.\n",
    "To address these issues, the geospatial extension package for openclean contains a specialized key generator and value standardizer that are demonstrated in the following. Take a look at the openclean.function.token.base.Tokens class, for example, if you want to create your own customized key generator.\n",
    "\n",
    "The following code uses the custom USStreetNameKey key generator and shows some of the values in the generated clusters. The generated clusters in general are significantly larger than the clusters that were generated using the default fingerprint algorithm. This shows one of the advantages of openclean in being customizable using domain specific functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484aeb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use a key generator that was specifically designed for street names.\n",
    "\n",
    "from openclean.cluster.key import KeyCollision\n",
    "from openclean_geo.address.usstreet import USStreetNameKey\n",
    "\n",
    "# In this example we take a different approach: we first extract the list of\n",
    "# distinct street names from the data file. We the apply transformations and\n",
    "# clustering directly on the list of names using three parallel threads.\n",
    "\n",
    "clusters = KeyCollision(func=USStreetNameKey(), threads=3).clusters(street_names)\n",
    "print_k_clusters(clusters, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data pipeline to dataframe for easy data manipulation\n",
    "#df = ds_full.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "CITY_COL = 'City'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6afef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from openclean.pipeline import stream\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "city_df = stream(datafile).select(CITY_COL).update(CITY_COL, str.upper).to_df()\n",
    "end = time.time()\n",
    "print(\"The execution time is \", end - start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print (a subset of) the distinct city names in the sample.\n",
    "\n",
    "city_df[CITY_COL].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1804354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a counter to maintain count of how many anomaly detection operators\n",
    "# classified each value as an outlier.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "ensemble = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac57c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fife different anomaly detection operators to the values in the city column.\n",
    "# Here we use a default value embedding that ignores the frequency of each value (since\n",
    "# in this NYC Open Dataset city names like NEW YORK and any of the five boroughs are\n",
    "# more frequent that other names).\n",
    "\n",
    "from openclean.embedding.feature.default import UniqueSetEmbedding\n",
    "from openclean.profiling.anomalies.sklearn import (\n",
    "    dbscan,\n",
    "    isolation_forest,\n",
    "    local_outlier_factor,\n",
    "    one_class_svm,\n",
    "    robust_covariance\n",
    ")\n",
    "\n",
    "for f in [dbscan, isolation_forest, local_outlier_factor, one_class_svm, robust_covariance]:\n",
    "    ensemble.update(f(city_df, CITY_COL, features=UniqueSetEmbedding()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edceb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output values that have been classified as outliers by at least three out of the\n",
    "# five operators.\n",
    "\n",
    "prev = 0\n",
    "for value, count in ensemble.most_common():\n",
    "    if count < 3:\n",
    "        break\n",
    "    if count < prev:\n",
    "        print()\n",
    "    if count != prev:\n",
    "        print('{}\\t{}'.format(count, value))\n",
    "    else:\n",
    "        print('\\t{}'.format(value))\n",
    "    prev = count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58566bf-f7a0-4319-9c56-927f5af2d491",
   "metadata": {},
   "source": [
    "<h3>Functional Dependencies<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0091ee24-64ae-4f18-a201-b6453f91e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data pipeline to dataframe for easy data manipulation\n",
    "df = ds_full.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309264b-2de6-4df3-825b-bc540408d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.operator.map.violations import fd_violations\n",
    "from openclean.operator.collector.count import distinct\n",
    "\n",
    "fd1_violations = fd_violations(df, ['Longitude', 'Latitude'],['Borough'])\n",
    "\n",
    "print('# of violations for FD(Longitude, Latitude -> Borough) is {}\\n'.format(len(fd1_violations)))\n",
    "for key, gr in fd1_violations.items():\n",
    "    print(gr[['Longitude', 'Latitude','Borough']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c53646-3f87-438f-9821-f230b26e3afe",
   "metadata": {},
   "source": [
    "We identify several violations in the above example. Clearly, it is row 583 as someone with domain knowledge should be able to point out that FD( -73.91246144190357  40.87512093148135) -> BRONX is incorrect. Let’s fix this using one of the repair strategies available to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951db6df-89ce-46df-9890-9f6f4fcfa2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.operator.collector.repair import Shortest, Vote, conflict_repair\n",
    "\n",
    "# Define the conflict resolution strategy. We use a majority vote for both RHS attributes.\n",
    "strategy = {'Borough': Vote(tiebreaker=Shortest())}\n",
    "\n",
    "# resolve the conflicts\n",
    "resolved = conflict_repair(conflicts=fd1_violations, strategy=strategy, in_order=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8245f38-0ae3-4613-8a31-2aaab6514557",
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_group = resolved[(resolved['Longitude']=='-73.91246144190357') & (resolved['Latitude']=='40.87512093148135')]\n",
    "\n",
    "fd2_violations = fd_violations(resolved, ['Longitude', 'Latitude'], ['Borough'])\n",
    "\n",
    "print('# of violations for FD(Longitude, Latitude -> Borough) is {}\\n'.format(len(fd2_violations)))\n",
    "print(violation_group['Longitude'],violation_group['Latitude'],violation_group['Borough'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43621c59-c213-4713-b6df-d3f4219431f0",
   "metadata": {},
   "source": [
    "Note: Since the data is very very large and it's infeasible to find each and every longitude and latitude corresponding each Borough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef77f87-a5cd-4532-ac35-08f837d12d5c",
   "metadata": {},
   "source": [
    "**Missing Values and Misspelled Data** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ec8b2a-aff4-4bde-91ef-697afb725ed2",
   "metadata": {},
   "source": [
    "Standardizing empty values in Borough column to Unkonwn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee44df-ebf8-401d-a85c-380101d74d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Borough'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9d4ffc",
   "metadata": {},
   "source": [
    "We see that there are empty values in Borough column. Hence, we update it using lambda function to standardize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1461b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.operator.transform.update import update\n",
    "from openclean.function.value.null import is_empty\n",
    "\n",
    "updated_misspelled = update(df, 'Borough', lambda x: 'Unknown' if is_empty(x) else x)\n",
    "\n",
    "updated_misspelled['Borough'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.operator.transform.filter import filter\n",
    "from openclean.function.eval.null import IsNotEmpty\n",
    "\n",
    "misspelled_data = filter(df, predicate=IsNotEmpty('Borough'))\n",
    "\n",
    "misspelled_data['Borough'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38283f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.function.matching.base import DefaultStringMatcher\n",
    "from openclean.function.matching.fuzzy import FuzzySimilarity\n",
    "from openclean.data.mapping import Mapping\n",
    "\n",
    "VOCABULARY = ['BROOKLYN' ,'MANHATTAN','STATEN ISLAND','BRONX', 'QUEENS']\n",
    "\n",
    "matcher = DefaultStringMatcher(\n",
    "    vocabulary=VOCABULARY,\n",
    "    similarity=FuzzySimilarity()\n",
    ")\n",
    "\n",
    "map = Mapping()\n",
    "for query in set(misspelled_data['Borough']):\n",
    "    map.add(query, matcher.find_matches(query))\n",
    "\n",
    "print(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.function.eval.domain import Lookup\n",
    "from openclean.operator.transform.update import update\n",
    "from openclean.function.eval.base import Col\n",
    "\n",
    "\n",
    "# fixed = update(misspelled_data, 'Borough', Lookup(columns=['Borough'], mapping=map.to_lookup(), default=Col('Borough')))\n",
    "misspelled_data = update(misspelled_data, 'Borough', Lookup(columns=['Borough'], mapping=map.to_lookup(), default=Col('Borough')))\n",
    "print(misspelled_data['Borough'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3294da-fb7a-4b49-8874-94fe8c523b63",
   "metadata": {},
   "source": [
    "<h5>Findings:</h5>\n",
    "We see that there are empty values in Borough column, and our code has replaced these missing values with Unknown.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802601b",
   "metadata": {},
   "source": [
    "**Testing Misspelling algorithm on top 10 rows**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea69a3c-2717-4ae4-8373-8ccf4ac7fc82",
   "metadata": {},
   "source": [
    "We will be testing top 10 data with a manipulated code to check if the algorithm is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87cc257-9c0f-4fd9-a11a-7919f3c5194b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dstop10 = ds_full.head()\n",
    "print(dstop10['Borough'])\n",
    "new_data = dstop10['Borough'][1]\n",
    "dstop10['Borough'][1] = 'BRUKLYN'\n",
    "print(\"\\n******************************** \\n\")\n",
    "print(dstop10['Borough'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4aff4b-7d53-4cd8-8a1c-ab9aedca5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.operator.transform.filter import filter\n",
    "from openclean.function.eval.null import IsNotEmpty\n",
    "\n",
    "misspelled_data_test = filter(dstop10, predicate=IsNotEmpty('Borough'))\n",
    "\n",
    "misspelled_data_test['Borough'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1e669-6662-4793-af99-bba2a6a00b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.function.matching.base import DefaultStringMatcher\n",
    "from openclean.function.matching.fuzzy import FuzzySimilarity\n",
    "from openclean.data.mapping import Mapping\n",
    "\n",
    "VOCABULARY = ['BROOKLYN' ,'MANHATTAN','STATEN ISLAND','BRONX', 'QUEENS']\n",
    "\n",
    "matcher = DefaultStringMatcher(\n",
    "    vocabulary=VOCABULARY,\n",
    "    similarity=FuzzySimilarity()\n",
    ")\n",
    "\n",
    "map = Mapping()\n",
    "for query in set(misspelled_data_test['Borough']):\n",
    "    map.add(query, matcher.find_matches(query))\n",
    "\n",
    "print(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc42c73-269d-47b5-9342-33f8ed3dc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.function.eval.domain import Lookup\n",
    "from openclean.operator.transform.update import update\n",
    "from openclean.function.eval.base import Col\n",
    "\n",
    "\n",
    "# fixed = update(misspelled_data, 'Borough', Lookup(columns=['Borough'], mapping=map.to_lookup(), default=Col('Borough')))\n",
    "misspelled_data_test = update(misspelled_data_test, 'Borough', Lookup(columns=['Borough'], mapping=map.to_lookup(), default=Col('Borough')))\n",
    "print(misspelled_data_test['Borough'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
